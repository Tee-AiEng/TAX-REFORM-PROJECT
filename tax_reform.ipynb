{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b1476f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (use FAISS for vector store)\n",
    "%pip install -q faiss-cpu langgraph langchain langchain-openai python-dotenv\n",
    "%pip install -q langchain-chroma pypdf python-docx\n",
    "%pip install -q langchain-community python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbafa5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from typing import Literal\n",
    "import os\n",
    "\n",
    "print(\"✅ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbdc144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found! Please set it in your .env file.\")\n",
    "\n",
    "print(\"✅ API key loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639e3af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.5,\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "print(f\"✅ LLM initialized: {llm.model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e434ae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all PDFs, DOCX and TXT files from the Tax_Project folder\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import os\n",
    "\n",
    "# Optional: python-docx may be required to read .docx files\n",
    "try:\n",
    "    from docx import Document as DocxReader\n",
    "    _HAS_DOCX = True\n",
    "except Exception:\n",
    "    _HAS_DOCX = False\n",
    "\n",
    "folder = 'Tax_Project'\n",
    "if not os.path.isdir(folder):\n",
    "    raise FileNotFoundError(f\"Folder not found: {folder}. Update path accordingly.\")\n",
    "\n",
    "documents = []\n",
    "\n",
    "for fname in sorted(os.listdir(folder)):\n",
    "    fpath = os.path.join(folder, fname)\n",
    "    if os.path.isdir(fpath):\n",
    "        continue\n",
    "    lower = fname.lower()\n",
    "    try:\n",
    "        if lower.endswith('.pdf'):\n",
    "            loader = PyPDFLoader(fpath)\n",
    "            # load() returns a list of Document objects (pages)\n",
    "            pages = loader.load()\n",
    "            for p in pages:\n",
    "                # add filename to metadata so you can trace source\n",
    "                p.metadata = {**getattr(p, 'metadata', {}), 'source': fname}\n",
    "                documents.append(p)\n",
    "        elif lower.endswith('.txt'):\n",
    "            with open(fpath, 'r', encoding='utf-8') as f:\n",
    "                text = f.read()\n",
    "            documents.append(Document(page_content=text, metadata={'source': fname}))\n",
    "        elif lower.endswith('.docx'):\n",
    "            if not _HAS_DOCX:\n",
    "                raise ImportError('python-docx is not installed. Run: python -m pip install python-docx')\n",
    "            doc = DocxReader(fpath)\n",
    "            text = '\\n'.join(p.text for p in doc.paragraphs)\n",
    "            documents.append(Document(page_content=text, metadata={'source': fname}))\n",
    "        else:\n",
    "            # skip other file types\n",
    "            continue\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Failed to load {fname}: {e}\")\n",
    "\n",
    "print(f\"✅ Loaded {len(documents)} documents from {folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fb18d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text splitter (Module 2 knowledge!)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,      # Characters per chunk\n",
    "    chunk_overlap=100     # Overlap to preserve context\n",
    ")\n",
    "\n",
    "# Split documents\n",
    "doc_splits = text_splitter.split_documents(pages)\n",
    "\n",
    "print(f\"✅ Created {len(doc_splits)} chunks\")\n",
    "print(f\"\\nSample chunk:\")\n",
    "print(f\"{doc_splits[0].page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76b4d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embeddings (using OpenAI)\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "print(\"✅ Embeddings model initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bc622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FAISS vector store\n",
    "faiss_path = \"./faiss_index_agentic_rag\"\n",
    "\n",
    "# Create vector store from documents (build in-memory FAISS index)\n",
    "vectorstore = FAISS.from_documents(documents=doc_splits, embedding=embeddings)\n",
    "\n",
    "# Persist FAISS index locally\n",
    "vectorstore.save_local(faiss_path)\n",
    "\n",
    "print(f\" FAISS vector store created with {len(doc_splits)} chunks\")\n",
    "print(f\"   Persisted to: {faiss_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42994b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def retrieve_documents(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for relevant documents in the knowledge base.\n",
    "    \n",
    "    Use this tool when you need information from the document collection\n",
    "    to answer the user's question. Do NOT use this for:\n",
    "    - General knowledge questions\n",
    "    - Greetings or small talk\n",
    "    - Simple calculations\n",
    "    \n",
    "    Args:\n",
    "        query: The search query describing what information is needed\n",
    "        \n",
    "    Returns:\n",
    "        Relevant document excerpts that can help answer the question\n",
    "    \"\"\"\n",
    "    # Use MMR (Maximum Marginal Relevance) for diverse results\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\"k\": 5, \"fetch_k\": 10}\n",
    "    )\n",
    "    \n",
    "    # Retrieve documents\n",
    "    results = retriever.invoke(query)\n",
    "    \n",
    "    if not results:\n",
    "        return \"No relevant documents found.\"\n",
    "    \n",
    "    # Format results\n",
    "    formatted = \"\\n\\n---\\n\\n\".join(\n",
    "        f\"Document {i+1}:\\n{doc.page_content}\"\n",
    "        for i, doc in enumerate(results)\n",
    "    )\n",
    "    \n",
    "    return formatted\n",
    "\n",
    "print(\"✅ Retrieval tool created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548ba0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tax calculator tool - simple progressive example\n",
    "# @tool\n",
    "# def tax_calculator(income: float, filing_status: str = 'single', year: int = 2025, deductions: float = 0.0) -> str:\n",
    "#     \"\"\"Calculate estimated tax using a simple progressive schedule.\"\"\"\n",
    "#     try:\n",
    "#         income = float(income)\n",
    "#         deductions = float(deductions)\n",
    "#     except Exception:\n",
    "#         return 'Error: income and deductions must be numeric.'\n",
    "\n",
    "#     taxable = max(0.0, income - deductions)\n",
    "\n",
    "#     # Example brackets (single filer approximation) - replace with jurisdiction-specific rules as needed\n",
    "#     brackets = [\n",
    "#         (0.10, 11000),\n",
    "#         (0.12, 44725),\n",
    "#         (0.22, 95375),\n",
    "#         (0.24, 182100),\n",
    "#         (0.32, 231250),\n",
    "#         (0.35, 578125),\n",
    "#         (0.37, float('inf'))\n",
    "#     ]\n",
    "\n",
    "#     prev = 0.0\n",
    "#     tax = 0.0\n",
    "#     breakdown = []\n",
    "#     for rate, upper in brackets:\n",
    "#         upper = float(upper)\n",
    "#         if taxable > prev:\n",
    "#             amount = min(taxable, upper) - prev\n",
    "#             segment_tax = amount * rate\n",
    "#             tax += segment_tax\n",
    "#             breakdown.append(f\"{amount:.2f} @ {int(rate*100)}% = {segment_tax:.2f}\")\n",
    "#         prev = upper\n",
    "#         if prev >= taxable:\n",
    "#             break\n",
    "\n",
    "#     effective_rate = (tax / income) if income > 0 else 0.0\n",
    "#     result = {\n",
    "#         'income': round(income,2),\n",
    "#         'deductions': round(deductions,2),\n",
    "#         'taxable_income': round(taxable,2),\n",
    "#         'tax': round(tax,2),\n",
    "#         'effective_rate': round(effective_rate,4),\n",
    "#         'breakdown': breakdown\n",
    "#     }\n",
    "#     import json\n",
    "#     return json.dumps(result)\n",
    "\n",
    "# print(\"✅ Tax calculator tool created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8314275",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = SystemMessage(content=\"\"\"You are a helpful assistant with access to a document retrieval tool. Prioritize documents in the Tax_Project folder for answers and cite them.\n",
    "\n",
    "RETRIEVAL DECISION RULES:\n",
    "\n",
    "DO NOT retrieve for:\n",
    "- Greetings, capability questions (e.g. \"What can you help with?\"), simple math or general knowledge, or casual conversation.\n",
    "\n",
    "DO retrieve for:\n",
    "- Questions asking for specific information that would be in documents.\n",
    "- Requests for facts, definitions, or explanations about specialized topics (tax policy, statutes, guidance).\n",
    "- Any question where citing sources would improve the answer.\n",
    "\n",
    "ADDITIONAL RULES:\n",
    "- Jurisdiction: ask the user if not specified; prefer documents applicable to the stated jurisdiction.\n",
    "- Recency: prefer documents published after 2015 unless the user requests otherwise.\n",
    "- Retrieval limits: retrieve at most 5 documents and include up to 300 characters per excerpt.\n",
    "- Citation format: append \" — Source: filename (page N)\" to any excerpt or claim derived from a document.\n",
    "- Conflicts: if documents disagree, list each source and explicitly state which you prefer and why.\n",
    "- Clarify: if the query is ambiguous, ask one clarifying question before retrieving.\n",
    "- Privacy: do not reveal private or sensitive content from documents unless the user explicitly permits it.\n",
    "\n",
    "When you retrieve documents, cite them in your answer. If documents do not contain the answer, say so.\n",
    "\"\"\")\n",
    "\n",
    "print(\"✅ System prompt configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b68a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind tools to LLM\n",
    "tools = [retrieve_documents, tax_calculator]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def assistant(state: MessagesState) -> dict:\n",
    "    \"\"\"Assistant node - decides whether to retrieve or answer directly.\"\"\"\n",
    "    messages = [system_prompt] + state['messages']\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {'messages': [response]}\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal['tools', '__end__']:\n",
    "    \"\"\"Decide whether to call tools or finish.\"\"\"\n",
    "    last_message = state['messages'][-1]\n",
    "    if last_message.tool_calls:\n",
    "        return 'tools'\n",
    "    return '__end__'\n",
    "\n",
    "print(\"✅ Agent nodes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e348ea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node('assistant', assistant)\n",
    "builder.add_node('tools', ToolNode(tools))\n",
    "\n",
    "# Define edges\n",
    "builder.add_edge(START, 'assistant')\n",
    "builder.add_conditional_edges(\n",
    "    'assistant',\n",
    "    should_continue,\n",
    "    {'tools': 'tools', '__end__': END},\n",
    ")\n",
    "builder.add_edge('tools', 'assistant')\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "agent = builder.compile(checkpointer=memory)\n",
    "\n",
    "print(\"✅ Agentic RAG system compiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334d463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the agentic RAG graph\n",
    "try:\n",
    "    display(Image(agent.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph: {e}\")\n",
    "    print(\"Graph: START → assistant → [if tool_call] → tools → assistant → END\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
